# 1. 동시성 시나리오

## 좌석 선점(예약)

---

 - 여러명의 사용자가 동시에 한 좌석을 점유하려고 하는 경우 좌석이 여러명에게 예약될 수 있다.

## 유저 포인트 잔액

---
 - 한명의 사용자가 본인의 계정으로 포인트 사용을 동시에 3번할 경우 포인트 잔액을 구하는 함수를
동시에 여러번 하게되면서 포인트가 정상적으로 차감되지 않을 수 있다.


## 두 기능의 공통점

--- 
 
 - 동시성 오류가 날 경우에 손해배상 등의 심각한 문제가 생길 수 있다.

## 두 기능의 차이점

 - 좌석 예약은 사용자들이 좌석 예약을 위해 달려들어서 충돌이 많이 발생한다.
 - 유저 포인트 잔액 조회는 포인트 사용과 충전과 연관되며 한 유저가 여러번 동시에 시도하는 경우에 문제가 발생한다
 - 유저 포인트는 충전을 결제와 같이 차후에 들어갈 경우를 생각하면 트랜잭션이 길어질 수 있다.


# 2. 동시성 제어 방법

## JPA 락

--- 
## 1. 낙관적 락

- 데이터 충돌이 낮을 경우
- 비즈니스적 중요도가 상대적으로 낮은 경우 적합
- 구현 난이도 낮음. DB 확장성 낮음

## 2. 비관적 락

- 데이터 충돌이 높을 경우
- 트랜잭션이 길 경우
- 구현 난이도 낮음. DB 확장성 낮음

## DB 격리 (MySql 예시)

- READ UNCOMMITTED: 다른 트랜잭션에서 커밋되지 않은 데이터를 읽어옴. 락이 없다고 보면됨
- READ COMMITTED: 커밋된 데이터만 읽을 수 있음, PESSIMISTIC_READ 락과 비슷하기 읽기 중에 수정 불가
- REPEATABLE READ: 트랜잭션 동안 동일한 데이터를 여러 번 읽어도 값이 안변하도록 보장. MySQL의 기본 격리 수준. PESSIMISTIC_WRITE인 X락이 사용될 수 있음
- SERIALIZABLE: 트랜잭션이 직렬로 수행. 모든 읽기에 S 락을 걸어 다른 트랜잭션이 접근하지 못하게 함.

### JPA 락과 DB 격리간의 관계: DB 격리 수준과 함께 낙관적 락이나 비관적 락을 조합해서 사용할 수 있다.

## 레디스

---

## 1. 분산 락 (Distributed Lock)

---

   Redlock은 Redis의 SET 명령어를 통해 분산 락을 얻고, TTL로 만료되도록 설정하는 방식입니다.

### Redlock의 장점

락을 TTL로 만료하도록 설정하여, 비정상적인 종료나 네트워크 오류로 인한 데드락 방지.
락을 해제할 때는 동일한 키와 값을 이용해 해제하여, 다른 클라이언트가 동일 키에 락을 설정하는 것을 방지.

### 구현 복잡도
단일 Redis 인스턴스를 사용해 SET NX PX 명령어만 잘 활용하면 되어서 낮은편

### 성능
레디스의 단순한 구조로 최소한의 네트워크 오버헤드로 락을 설정하고 해제 가능하고 높은 처리량을 보여줌

### 효율성과 리스크
단일 어플리케이션에서는 단순하고 빠르고 높은 처리량을 보여주지만 Single Point Failure가 될 수 있다. 레디스 인스턴스가 죽으면 큰일남


2. 세마포어, 스핀락 (Semaphore, Spinlock)
   여러 개의 리소스를 동시에 제어할 수 있게 해주는 동시성 제어 메커니즘, 한 번에 일정한 수의 클라이언트가 자원을 이용할 수 있도록 허용

### Redis 세마포어 구현:
카운터를 이용한 방식: 특정 key의 값이 허용된 리소스 수보다 작을 때에만 자원을 획득이 가능
셋(Set)을 이용한 방식: SETNX를 사용하여 클라이언트가 자원을 획득할 때마다 셋에 추가, 자원을 해제할 때는 셋에서 제거

### 구현 복잡도
Redis 세마포어는 Redlock보다 복잡함. 특정 key에 세마포어 값을 설정하고 이 값의 동시 접근을 제어해야함. 그렇지만 트랜잭션 없이 Redis의 INCR나 DECR 명령어로 구현이 가능

### 성능
Redlock과 다르게 여러 클라이언트의 요청을 분산하여 처리할 수 있지만 락 해제를 누락하면 자원이 고갈될 수 있어서 주의롤 요함, 세마포어 값을 제어하는 과정에서 약간의 오버헤드가 있음

### 효율성과 리스크
복수의 자원 접근이 필요한 경우에 적합. 락 관리와 해제에 실패할 경우 문제가 발생할 수 있어서 레디스 인스턴스와 서버간의 연결 상태가 안좋으면 문제가 발생.



## 3. Pub/Sub를 이용한 이벤트 기반 락

---

   Redis의 Pub/Sub 기능을 사용해 특정 자원에 대한 락을 이벤트로서 처리하는 방식

### 주요 개념:
자원에 락이 걸릴 때, 다른 클라이언트는 대기 큐에서 대기.
자원이 해제되면, Pub/Sub를 통해 모든 구독자에게 알림을 보내 다음 클라이언트가 락을 획득하게 합니다

### 구현 복잡도
Pub/Sub는 이벤트 기반으로 동시성 문제를 해결할 수 있지만 sub인 클라이언트 쪽 추가 구현이 필요. 자원 접근 대기 중의 클라이언트 관리가 필요하면서, Pub/Sub 구조가 어려움.

### 성능
Pub/Sub은 오버헤드가 적고, 빠른 속도로 메시지를 주고받을 수 있어 이벤트 제어에 효율적임

### 효율성과 리스크
비동기성 작업에는 좋지만 클라이언트가 자원의 대기 상태를 관리해야 하므로 클라이언트의 리소스 소모가 클 수 있음. 여러 클라이언트의 동시접근 케이스에는 좋지만 단일 자원 관리에서는 별로임. 레디스가 가지고 있는 구조적 한계로서 유실된 데이터에 대한 복구나 보상 트랜잭션이 힘듬.

## 4. Redis Streams를 이용한 대기열 기반 제어

---
Redis Streams를 사용해 대기열로서 작업을 순차적으로 처리. 락 자체를 없애는 방식.

### 1. 구현 복잡도
   Redis Streams를 이용한 대기열 제어는 난이도가 높다.

스트림 생성 및 항목 추가: 스트림에 새 이벤트를 추가하는 기능
소비자 그룹 설정: 스트림의 병렬 처리를 위한 소비자 그룹의 생성
메시지 처리 및 인식: 작업 처리의 인식(Acknowledgement)과 중복 처리방지.
자동 재처리: 미완료나 소비되지 않은 작업에 대한 재처리가 되도록 설계.

위의 모든 구성을 이해하고 구현하는데 시간이 요구됨

### 2. 성능
   Redis Streams의 빠르고 높은 처리량. 동시에 여러 클라이언트가 접근할 수 있는 좋은 성능을 보여줌

### 3. 효율성과 리스크
  순차 작업처리(FIFO), 자동 재시도와 어느 정도의 안정성이 지원됨. 여전히 데이터 유실에 대한 해결책이 마땅치 않음

# 카프카

Kafka는 분산 스트리밍 플랫폼로서, 소비자(consumer) 그룹과 파티션(partition)을 활용하여 동시성 문제를 해결함

## 1. 소비자 그룹 (Consumer Group)
 
### 구조:
  Kafka가 자동으로 파티션을 소비자 그룹의 각 소비자에게 할당하여 이벤트를 순차적으로 처리.
각 파티션은 하나의 소비자에 의해 처리되므로 자연스럽게 동시성 문제가 없어짐. 하나의 파티션이 장애로 인해 작동하지 않으면 다른 소비자가 해당 파티션을 처리하도록 되어있음.

### 관리 포인트:
  파티션과 소비자 그룹 수를 잘 조절하여야함

### 2. 파티션 수 조정

### 구조:

동시성 제어 방식:
Kafka 클러스터 설정 시, 동시성이 필요한 토픽에 더 많은 파티션을 할당이 가능하다

### 관리 포인트:
파티션 수가 늘어나면 클러스터의 데이터 분산 및 관리 복잡도가 올라가서 너무 많은 파티션은 클러스터에 과부하를 줄 수 있음.

### 3. 오프셋(offset) 관리로 동시성 제어 및 장애 처리
   Kafka는 각 메시지의 위치를 **오프셋(offset)**으로 관리하여 동시성과 장애 복구를 할 수 있음. 소비자는 자신의 오프셋을 커밋(commit)하여 최종적인 메시지의 처리 위치를 기록할 수 있음

### 구조: 

동시성 제어 방식:
특정 파티션의 오프셋을 관리하여 여러 소비자가 동시에 여러 파티션 처리가 가능함.
파티션 내에서 메시지 순서가 보장되므로, 순차적 처리가 필요한 경우에도 동시성 제어가 가능

### 4. 멀티스레드 소비자를 통한 동시성 제어
   Kafka에서 멀티스레드 소비자를 구성하여 하나의 소비자가 여러 스레드로 메시지를 처리할 수 있음. 그러나 Kafka는 소비자-파티션 간 1:1 매핑을 기본으로 하기 때문에, 어플리케이션에서 멀티쓰레드 관리를 하여야함.

### 구조: 
  하나의 소비자가 여러 스레드를 사용해 메시지를 처리, 각 스레드는 큐를 통해 파티션의 메시지를 가져가 처리.
  멀티스레드 소비자는 개발자가 스레드 관리, 큐 관리, 장애 복구 및 오프셋 커밋 관리 등의 이유로 구현이 복잡할 수 있습니다.

### 5. 트랜잭션 기반 메시지 처리로 동시성 제어

### 구조:
  소비자가 여러 파티션의 메시지를 동시에 처리할 때, 트랜잭션을 사용해 해당 처리를 원자적으로 수행할 수 있음.
소비자는 프로듀서와 협력하여 트랜잭션을 시작하고, 처리 완료 후 커밋함. 트랜잭션이 비정상적으로 끝날 경우 다른 소비자가 해당 트랜잭션을 처리 할 수 있음.
중복처리가 없는 안전한 병렬 처리르 지원함.
트랜잭션 설정에 따른 성능 저하와 관리 포인트가 늘어남.

| 방법                           | 구현 복잡도 | 성능      | 특징                                        |
|--------------------------------|-------------|-----------|---------------------------------------------|
| 소비자 그룹을 통한 동시성 제어 | 중간        | 높음      | 파티션 단위로 소비자 그룹 내 병렬 처리 가능 |
| 파티션 수 조정으로 동시성 제어 | 낮음        | 높음      | 소비자 수 증가에 따라 파티션 수 필요        |
| 오프셋 관리로 장애 복구 지원   | 중간        | 높음      | 오프셋 관리로 중복 처리 및 손실 방지 가능   |
| 멀티스레드 소비자              | 높음        | 중간      | 소비자 1개로 다수 파티션 병렬 처리          |
| 트랜잭션 기반 메시지 처리      | 높음        | 중간~낮음 | 메시지 일관성 및 중복 처리 방지 가능        |




## 결론

카프카 방식은 카프카를 세팅하는 비용과 프로젝트를 카프카에 맞게 리팩토링을 해야해서 구현 비용이 너무 높으므로 패스.

레디스를 이용한 stream, pub/sub은 데이터 유실 가능성이 있고 pub/sub 방식의 높은 구현 난이도로 패스

레디스 스핀락은 현재 좌석 예약과 유저 포인트에서는 복수 클라이언트 접근이 필요한 것이 아니므로 패스

남은 방식은 DB락과 레디스 분산락 방식이다.

레디스 분산락은 pub/sub을 사용하지만 락의 TTL을 믿고 구현을 할 수 있다.

동시의 많은 사용자가 접근을 시도하면서 좋은 성능을 요구하는 좌석 예약에는 레디스 분산락을 이용하고

한명의 사용자가 한개의 자원에 여러번 동시에 접근하는 동시성 문제를 가진 유저 포인트 조회에는 비관적 락을 이용해볼 예정이다.